{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "#Serai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_score(guess):\n",
    "    for i, letter in enumerate(guess):\n",
    "        if letter == solution[i]:\n",
    "            guess_scores[i] = g\n",
    "            print(g)\n",
    "        elif letter in solution:\n",
    "            guess_scores[i] = y\n",
    "            print(y)\n",
    "        else:\n",
    "            misses.append(letter)\n",
    "            guess_scores[i] = m\n",
    "            print(m)\n",
    "    return guess_scores, misses\n",
    "# print(misses)\n",
    "# print(guess_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words(options, misses, guess, guess_scores):\n",
    "    removes = []\n",
    "    print(f\"length of options before anything: {len(options)}\\n\")\n",
    "\n",
    "    for word in options:\n",
    "        for letter in misses:\n",
    "            if letter in word:\n",
    "                # print(word, letter)\n",
    "                removes.append(word)\n",
    "                break\n",
    "\n",
    "    options_2 = [x for x in options if x not in removes]\n",
    "    print(f\"length of options after misses: {len(options_2)}\\n\")\n",
    "\n",
    "    for word in options_2:\n",
    "        for i, score in enumerate(guess_scores):\n",
    "            if score == 2:\n",
    "                true_letter = guess[i]\n",
    "                if word[i] != true_letter:\n",
    "                    # print(word, guess, true_letter)\n",
    "                    removes.append(word)\n",
    "                    break\n",
    "\n",
    "    options_3 = [x for x in options_2 if x not in removes]\n",
    "    print(f\"length of options after misses and green letter: {len(options_3)}\\n\")\n",
    "\n",
    "    yellow_letters = []\n",
    "    yl = {}\n",
    "    for i, digit in enumerate(guess_scores):\n",
    "        if digit == 1:\n",
    "            yellow_letters.append(guess[i])\n",
    "            yl[guess[i]] = i\n",
    "    \n",
    "    for word in options_3:\n",
    "        for letter in yellow_letters:\n",
    "            if letter not in word:\n",
    "                removes.append(word)\n",
    "                break\n",
    "    options_4 = [x for x in options_3 if x not in removes]\n",
    "\n",
    "    print(f\"length of options after misses, green letter, and yellow letter: {len(options_4)}\\n\")\n",
    "\n",
    "    for word in options_4:\n",
    "        for letter in yl:\n",
    "            if word[yl[letter]] == letter:\n",
    "                removes.append(word)\n",
    "                break\n",
    "\n",
    "    options_5 = [x for x in options_4 if x not in removes]\n",
    "\n",
    "    print(f\"length of options after misses, green letter, yellow letter, and yellow letter placement elimination: {len(options_5)}\\n\")\n",
    "\n",
    "    return options_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_score(options, guess, guess_scores):\n",
    "    scores = {}\n",
    "    for word in options:\n",
    "        score = 0\n",
    "        for i, letter in enumerate(word):\n",
    "            if guess_scores[i] == 0:\n",
    "                continue\n",
    "            elif guess_scores[i] == 1:\n",
    "                if guess[i] in word:\n",
    "                    score += guess_scores[i]\n",
    "            elif guess_scores[i] == 2:\n",
    "                if letter == guess[i]:\n",
    "                    score += guess_scores[i]\n",
    "        scores[word] = score\n",
    "\n",
    "    best_score = max(scores.values())\n",
    "    return_options = []\n",
    "    for word in options:\n",
    "        if scores[word] == best_score:\n",
    "            return_options.append(word)\n",
    "    # print(return_options)\n",
    "    return return_options\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_words = 'ABACK ABASE ABATE ABBEY ABOUT ABOVE ABYSS ACRID ACTOR ACUTE ADMIT ADOBE ADOPT ADORE ADULT AGAIN AGAPE AGATE AGENT AGILE AGLOW AGONY AGREE AHEAD ALBUM ALIEN ALIKE ALLOW ALOFT ALONE ALOUD ALPHA ALTAR ALTER AMBER AMISS AMPLE ANGEL ANGER ANGRY ANODE ANTIC AORTA APHID APPLE APPLY APRON APTLY ARBOR ARDOR ARGUE AROMA ASIDE ASKEW ASSET ATOLL ATONE AUDIO AUDIT AVAIL AVERT AWAIT AWAKE AWFUL AXIOM AZURE BADGE BADLY BAGEL BAKER BALSA BANAL BARGE BASIC BATHE BATON BATTY BAYOU BEACH BEADY BEAST BEEFY BEGET BEGIN BEING BELCH BELIE BELLY BELOW BENCH BERET BERTH BESET BINGE BIOME BIRCH BIRTH BLACK BLAME BLAND BLEAK BLEED BLEEP BLOKE BLOWN BLUFF BLURB BLURT BLUSH BOOBY BOOST BOOZE BOOZY BORAX BOUGH BRAID BRAKE BRASH BRAVE BREAD BREAK BRIAR BRIBE BRIDE BRINE BRING BRINK BRISK BROKE BROOK BROOM BRUSH BUGGY BULLY BUNCH BURLY CACAO CACHE CANDY CANNY CANOE CAPER CARAT CARGO CARRY CAROL CATCH CATER CAULK CAUSE CEDAR CHAFE CHAMP CHANT CHARD CHARM CHART CHEAT CHEEK CHEST CHIEF CHILL CHIME CHOIR CHOKE CHORD CHUNK CHUTE CIDER CIGAR CINCH CIRCA CIVIC CLASS CLEAN CLEAR CLERK CLICK CLING CLOCK CLOSE CLOTH CLOWN CLUCK COACH COAST COCOA COLON COMET COMMA CONDO CONIC CORNY COULD COUNT COVET COWER COYLY CRAMP CRANE CRANK CRASS CRATE CRAVE CRAZE CRAZY CREAK CREDO CREPT CRIME CRIMP CROAK CRONE CROSS CRUMB CRUST CURLY CYNIC DADDY DANCE DANDY DEATH DEBUG DELTA DELVE DENIM DEPOT DEPTH DIGIT DINER DISCO DITTO DODGE DONOR DONUT DOUBT DOWRY DOZEN DRAIN DREAM DRINK DRIVE DROLL DROOP DUCHY DUTCH DUVET DWARF DWELL DWELT EARTH EGRET EJECT ELDER ELOPE ELUDE EMAIL EMPTY ENEMA ENJOY ENNUI ENTER EPOCH EPOXY EQUAL ERODE ERROR ESSAY ETHIC ETHOS EVADE EVERY EXACT EXCEL EXERT EXIST EXTRA EXULT FARCE FAULT FAVOR FEAST FEIGN FERRY FEWER FIELD FIEND FIFTY FINER FIRST FISHY FIXER FJORD FLAIL FLAIR FLANK FLARE FLASK FLESH FLICK FLING FLIRT FLOAT FLOCK FLOOD FLOOR FLORA FLOSS FLOUT FLUFF FLUME FLYER FOCAL FOCUS FOGGY FOLLY FORAY FORGE FORGO FORTH FOUND FOYER FRAME FRANK FRESH FROCK FRONT FROST FROTH FROZE FUNGI GAMER GAMMA GAUDY GAUZE GAWKY GECKO GHOUL GIANT GIDDY GIRTH GIVEN GLASS GLAZE GLEAN GLOAT GLOOM GLORY GLOVE GLYPH GNASH GOLEM GONER GOOSE GORGE GOUGE GRADE GRAIL GRAND GRAPH GRATE GREAT GREEN GREET GRIEF GRIME GRIMY GRIPE GROIN GROUP GROUT GROVE GROWL GRUEL GUANO GUARD GUEST GUIDE GUILD GULLY GUPPY HAIRY HAPPY HATCH HATER HAVOC HEADY HEART HEATH HEIST HELIX HELLO HERON HINGE HOARD HOBBY HOMER HORDE HORSE HOTEL HOUND HOWDY HUMAN HUMID HUMOR HUMPH HUNKY HURRY HUTCH HYPER IGLOO IMPEL INANE INDEX INEPT INERT INFER INPUT INTER IONIC IRATE IRONY ISLET ITCHY IVORY JAUNT JAZZY JOKER JOUST JUDGE KARMA KAYAK KAZOO KEBAB KHAKI KIOSK KNEEL KNELT KNOCK KNOLL KOALA LABEL LABOR LAPEL LAPSE LARVA LATTE LAYER LEAFY LEAKY LEAPT LEASH LEAVE LEDGE LEERY LEMON LIBEL LIGHT LILAC LIMIT LINEN LIVER LOCUS LOFTY LOGIC LOOPY LOSER LOVER LOWLY LOYAL LUCKY LUNAR LUSTY LYING MADAM MAGIC MAGMA MAIZE MAJOR MANIA MANLY MANOR MAPLE MARCH MARRY MARSH MASON MASSE MATEY MAXIM MAYBE MEALY MEANT MEDAL MERCY MERIT MERRY METAL METRO MIDGE MIDST MIMIC MINCE MODEL MOIST MOLAR MONEY MONTH MOOSE MOSSY MOTOR MOTTO MOULT MOUNT MOURN MOUSE MOVIE MUCKY MUMMY MUSIC NAIVE NANNY NASTY NATAL NAVAL NEEDY NIGHT NINJA NINTH NOBLE NOISE NYMPH OCCUR OCEAN OFFAL OLDER OLIVE ONION ONSET OPERA OTHER OUGHT OUTDO OXIDE PANEL PANIC PAPER PARER PARRY PARTY PATTY PAUSE PEACE PEACH PERCH PERKY PHASE PHONY PHOTO PIANO PICKY PIETY PILOT PINEY PINKY PINTO PIQUE PITHY PIXEL PIXIE PLANK PLANT PLATE PLAZA PLEAT PLUCK PLUNK POINT POISE POKER POLKA POLYP POUND POWER PRICK PRIDE PRIME PRIMO PRINT PRIZE PROBE PROVE PROXY PULPY PURGE QUALM QUART QUEEN QUERY QUEST QUEUE QUICK QUIET QUIRK QUOTE RADIO RAINY RAMEN RANCH RANGE RATIO RAYON REACT REBUS REBUT RECAP REGAL RENEW REPAY RETCH RETRO RETRY REVEL RHINO RHYME RIGHT RIPER RIVAL ROBIN ROBOT ROCKY RODEO ROGUE ROOMY ROUGE ROUND ROUSE ROYAL RUDDY RUDER RUPEE RUSTY SAINT SALAD SALSA SASSY SAUTE SCALD SCARE SCARF SCOLD SCORN SCOUR SCOUT SCRAP SCRUB SEDAN SEEDY SERVE SEVER SHAKE SHALL SHAME SHARD SHAWL SHINE SHIRE SHIRK SHORN SHOWN SHOWY SHRUB SHRUG SHYLY SIEGE SIGHT SISSY SKILL SKIMP SKIRT SKUNK SLATE SLEEK SLOSH SLOTH SLUMP SLUNG SMART SMASH SMEAR SMELT SMILE SMIRK SMITE SNACK SNAFU SNAIL SNAKY SNARE SNARL SNEAK SNOUT SOGGY SOLAR SOLVE SONIC SOUND SOWER SPACE SPADE SPELL SPEND SPICE SPICY SPIEL SPIKE SPILL SPIRE SPLAT SPOKE SPRAY SPURT SQUAD SQUAT STAFF STAGE STAID STAIR STALE STAND START STEAD STEED STEIN STICK STING STINK STOCK STOMP STONE STOOL STORE STORY STOUT STOVE STRAP STRAW STUDY STYLE SUGAR SULKY SURER SURLY SWEAT SWEEP SWEET SWILL SWINE SWIRL SYRUP TACIT TANGY TAPER TAPIR TARDY TASTE TASTY TAUNT TEASE TEMPO TENTH TEPID THEIR THEME THERE THIEF THINK THIRD THORN THOSE THROW THUMB THUMP THYME TIARA TIBIA TIGER TILDE TIPSY TODAY TONIC TOPAZ TORSO TOTEM TOUGH TOXIC TRACE TRACT TRADE TRAIN TRAIT TRASH TRAWL TREAT TREND TRIAD TRICE TRITE TROLL TROPE TROVE TRUSS TRUST TRUTH TRYST TWANG TWEED TWICE TWINE ULCER ULTRA UNCLE UNDER UNDUE UNFED UNFIT UNIFY UNITE UNLIT UNMET UNTIE UNTIL UNZIP UPSET USAGE USHER USING USUAL USURP UTTER VAGUE VALET VALID VENOM VERVE VIGOR VIOLA VIRAL VITAL VIVID VODKA VOICE VOTER VOUCH WACKY WALTZ WASTE WATCH WEARY WEDGE WHACK WHALE WHEEL WHELP WHERE WHIFF WHILE WHINE WHIRL WHISK WHOOP WINCE WINDY WOKEN WOOER WORDY WORLD WORRY WORSE WOVEN WRATH WRITE WRONG WROTE WRUNG YACHT YEARN YIELD YOUTH ZESTY'\n",
    "# past_words = raw_words.split(' ')\n",
    "# past_words = [word.lower() for word in past_words]\n",
    "# # past_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': 12.02,\n",
       " 't': 9.1,\n",
       " 'a': 8.12,\n",
       " 'o': 7.68,\n",
       " 'i': 7.31,\n",
       " 'n': 6.95,\n",
       " 's': 6.28,\n",
       " 'r': 6.02,\n",
       " 'h': 5.92,\n",
       " 'd': 4.32,\n",
       " 'l': 3.98,\n",
       " 'u': 2.88,\n",
       " 'c': 2.71,\n",
       " 'm': 2.61,\n",
       " 'f': 2.3,\n",
       " 'y': 2.11,\n",
       " 'w': 2.09,\n",
       " 'g': 2.03,\n",
       " 'p': 1.82,\n",
       " 'b': 1.49,\n",
       " 'v': 1.11,\n",
       " 'k': 0.69,\n",
       " 'x': 0.17,\n",
       " 'q': 0.11,\n",
       " 'j': 0.1,\n",
       " 'z': 0.07}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_letter_freq():\n",
    "\n",
    "    s = '''Letter\tCount\t \tLetter\tFrequency\n",
    "    E\t21912\t \tE\t12.02\n",
    "    T\t16587\t \tT\t9.10\n",
    "    A\t14810\t \tA\t8.12\n",
    "    O\t14003\t \tO\t7.68\n",
    "    I\t13318\t \tI\t7.31\n",
    "    N\t12666\t \tN\t6.95\n",
    "    S\t11450\t \tS\t6.28\n",
    "    R\t10977\t \tR\t6.02\n",
    "    H\t10795\t \tH\t5.92\n",
    "    D\t7874\t \tD\t4.32\n",
    "    L\t7253\t \tL\t3.98\n",
    "    U\t5246\t \tU\t2.88\n",
    "    C\t4943\t \tC\t2.71\n",
    "    M\t4761\t \tM\t2.61\n",
    "    F\t4200\t \tF\t2.30\n",
    "    Y\t3853\t \tY\t2.11\n",
    "    W\t3819\t \tW\t2.09\n",
    "    G\t3693\t \tG\t2.03\n",
    "    P\t3316\t \tP\t1.82\n",
    "    B\t2715\t \tB\t1.49\n",
    "    V\t2019\t \tV\t1.11\n",
    "    K\t1257\t \tK\t0.69\n",
    "    X\t315\t \tX\t0.17\n",
    "    Q\t205\t \tQ\t0.11\n",
    "    J\t188\t \tJ\t0.10\n",
    "    Z\t128\t \tZ\t0.07\n",
    "    '''\n",
    "\n",
    "    raw_df = pd.DataFrame([x.split('\\t') for x in s.split('\\n') if x != ''], columns=['letter', 'count', '','letter2', 'frequency'])\n",
    "    raw_df.drop(columns=['', 'count','letter2'], inplace=True)\n",
    "    raw_df.drop(index=0, inplace=True)\n",
    "    df = raw_df.set_index('letter')\n",
    "    d = df.to_dict()['frequency']\n",
    "    keys = [x.strip().lower() for x in d]\n",
    "    return {key:float(f) for (key,f) in zip(keys, d.values()) if key !=''}\n",
    "\n",
    "get_letter_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate confidence based strictly on how many green and yellow letters there are\n",
    "\n",
    "def green_yellow_confidence(green_count, yellow_count, pool_size, total_letters=5, weight_green=5, weight_yellow=2.5):\n",
    "    # Avoid division by zero\n",
    "    if pool_size == 0:\n",
    "        return 0\n",
    "\n",
    "    # TODO: add a factor for the remaining words in the alphabet\n",
    "    # TODO: add a factor for the popularity of the letter (z should be lower in rank than s)\n",
    "\n",
    "    score = ((green_count * weight_green + yellow_count * weight_yellow) / total_letters) * (1 / pool_size)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resin': 0.719, 'hucky': 0.143, 'queue': -0.001}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_confidence_dict(guess, words, guess_scores):\n",
    "    word_info = []\n",
    "    \n",
    "    # counting the amount of green and yellow letters in the guess\n",
    "    gl = [x for i,x in enumerate(guess) if guess_scores[i] == 2]\n",
    "    yl = [x for i,x in enumerate(guess) if guess_scores[i] == 1]\n",
    "    \n",
    "    # building a dictionary of the remaining guesses and \n",
    "    # how many green and yellow letters they have in common\n",
    "    # with the guess\n",
    "    \n",
    "    for word in words:\n",
    "        s_word = list(set(word))    # TODO: right now we are assuming that there are no double letters\n",
    "        yellow_letters = 0\n",
    "        green_letters = 0\n",
    "        for i, letter in enumerate(s_word):\n",
    "            if letter in gl:\n",
    "                green_letters += 1\n",
    "            elif letter in yl:\n",
    "                yellow_letters += 1\n",
    "        # print(word, green_letters, yellow_letters)\n",
    "        word_info.append({word: {'green': green_letters, 'yellow': yellow_letters}})\n",
    "\n",
    "    confidence_dict = {}\n",
    "    for d in word_info:\n",
    "        for word in d:\n",
    "            confidence_dict[word] = green_yellow_confidence(d[word]['green'], d[word]['yellow'], len(words))\n",
    "    \n",
    "    letter_freq = get_letter_freq()\n",
    "\n",
    "    # compiling a dictionary of each word and the sum of frequency score of each of its letters\n",
    "\n",
    "    freq_scores = {}\n",
    "    for word in words:\n",
    "        freq_scores[word] = 0\n",
    "        for letter in word:\n",
    "            freq_scores[word] += letter_freq[letter]\n",
    "\n",
    "    # adding the frequency score to the confidence score\n",
    "\n",
    "    for word in confidence_dict:\n",
    "        confidence_dict[word] += (freq_scores[word] * 0.01)\n",
    "\n",
    "    # adding a penalty for words with multiple letters\n",
    "\n",
    "    for word in confidence_dict:\n",
    "        if len(set(word)) < len(word):\n",
    "            confidence_dict[word] -= (0.15 * (len(word)-len(set(word))))\n",
    "\n",
    "    # TODO: manipulate the score based on amount of letters in the alphabet remaining\n",
    "\n",
    "    for key in confidence_dict:\n",
    "        confidence_dict[key] = round(confidence_dict[key], 3)\n",
    "    \n",
    "    return dict(sorted(confidence_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "build_confidence_dict('audio', ['hucky','queue','resin'], [0, 0, 0, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = get('https://www.wordunscrambler.net/word-list/wordle-word-list')\n",
    "# bs = BeautifulSoup(response.text, 'html.parser')\n",
    "# all_a_html = bs.find_all('a')\n",
    "# all_a = [a.text for a in all_a_html]\n",
    "# all_words = [word for word in all_a if len(word) == 5]\n",
    "# pool = [word for word in all_words if word not in past_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to update the options every guess\n",
    "\n",
    "# download the text files so it looks purty\n",
    "\n",
    "# make a threshold for confidence scores (if it's lower than x, guess a word that will give lots of information)\n",
    "\n",
    "# make an information gain calculator\n",
    "\n",
    "# past words are solid, sushi, scope, tawny, resin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "guess: bunch\n",
      "\n",
      "misses: ['b', 'u', 'c', 'h']\n",
      "\n",
      "guess_scores: [0, 0, 1, 0, 0]\n",
      "\n",
      "length of options before anything: 1423\n",
      "\n",
      "length of options after misses: 695\n",
      "\n",
      "length of options after misses and green letter: 695\n",
      "\n",
      "length of options after misses, green letter, and yellow letter: 201\n",
      "\n",
      "length of options after misses, green letter, yellow letter, and yellow letter placement elimination: 153\n",
      "\n",
      "\n",
      "\n",
      "final option(s) ranked by confidence level:  [('stern', 0.407), ('leant', 0.405), ('inlet', 0.397), ('snore', 0.393), ('resin', 0.389), ('risen', 0.389), ('siren', 0.389), ('often', 0.384), ('satin', 0.381), ('stain', 0.381)]\n",
      "\n",
      "top 10 final option(s) ranked by word popularity: ['women', 'learn', 'going', 'never', 'login', 'event', 'often', 'taken', 'known', 'along']\n",
      "\n",
      "\n",
      "guess: stern\n",
      "\n",
      "misses: ['t']\n",
      "\n",
      "guess_scores: [1, 0, 1, 1, 2]\n",
      "\n",
      "length of options before anything: 153\n",
      "\n",
      "length of options after misses: 121\n",
      "\n",
      "length of options after misses and green letter: 53\n",
      "\n",
      "length of options after misses, green letter, and yellow letter: 3\n",
      "\n",
      "length of options after misses, green letter, yellow letter, and yellow letter placement elimination: 2\n",
      "\n",
      "\n",
      "\n",
      "final option(s) ranked by confidence level:  [('resin', 1.636), ('risen', 1.636)]\n",
      "\n",
      "top 10 final option(s) ranked by word popularity: ['resin', 'risen']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_options = pd.read_csv('options.csv')['word'].tolist()\n",
    "options = all_options\n",
    "\n",
    "keep_guessing = True\n",
    "count = 0\n",
    "\n",
    "while keep_guessing:\n",
    "    count += 1\n",
    "    guess = input('What did we guess?')\n",
    "    misses = input('What letters did we miss?')\n",
    "    guess_scores = input('What were the scores?')\n",
    "    misses = [x for x in misses]\n",
    "    guess_scores = [int(x) for x in guess_scores]\n",
    "\n",
    "    print(f'\\nguess: {guess}\\n')\n",
    "    print(f'misses: {misses}\\n')\n",
    "    print(f'guess_scores: {guess_scores}\\n')\n",
    "\n",
    "    o = remove_words(options, misses, guess, guess_scores)\n",
    "    # print(f'options: {options}\\n')\n",
    "    final_options = filter_by_score(o, guess, guess_scores)\n",
    "    d = build_confidence_dict(guess, final_options, guess_scores)\n",
    "    print(f'\\n\\nfinal option(s) ranked by confidence level:  {list(d.items())[:10]}\\n')\n",
    "    print(f'top 10 final option(s) ranked by word popularity: {final_options[:10]}\\n')\n",
    "\n",
    "    if input('Take a look at the options below and input your guess. If we guessed correctly, type \"correct\", otherwise, hit enter') == 'correct':\n",
    "        count +=1\n",
    "        keep_guessing = False\n",
    "        correct_word = input(f'\\nNice job! We got it in {count} guesses! What was the correct word?\\n')\n",
    "        continue\n",
    "    \n",
    "    options = final_options\n",
    "    # print(len(options), len(all_options))\n",
    "\n",
    "all_options.remove(correct_word)\n",
    "df = pd.DataFrame(all_options, columns=['word'])\n",
    "df.to_csv('options.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
